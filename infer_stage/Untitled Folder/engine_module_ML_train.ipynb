{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f0b6ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Saved: C:\\engine_module_pipeline\\infer_stage\\artifacts\\model_input_contract.json\n"
     ]
    }
   ],
   "source": [
    "# T-1 — Paths, imports, device, canonical feature contract\n",
    "\n",
    "import os, json, math, time, uuid, warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ----- Paths -----\n",
    "ROOT         = Path(r\"C:\\engine_module_pipeline\")\n",
    "INFER_STAGE  = ROOT / \"infer_stage\"\n",
    "ARTIFACTS    = INFER_STAGE / \"artifacts\"\n",
    "DATA_CSV     = ROOT / r\"data\\csv\\engine_module.csv\"\n",
    "\n",
    "ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----- Device -----\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# ----- Canonical feature list (order-sensitive, used by ALL models) -----\n",
    "FEATURES_JSON_CANON = ROOT / r\"engine_module_artifacts\\features.json\"\n",
    "if FEATURES_JSON_CANON.exists():\n",
    "    features = json.loads(FEATURES_JSON_CANON.read_text(encoding=\"utf-8\"))\n",
    "    if isinstance(features, dict) and \"features\" in features:\n",
    "        features = features[\"features\"]\n",
    "else:\n",
    "    # Fallback: hardcode (must match your canonical order)\n",
    "    features = [\n",
    "        \"Air_Fuel_Ratio_Commanded_:1\",\"Air_Fuel_Ratio_Measured_:1\",\n",
    "        \"Catalyst_Temperature__Bank_1_Sensor_1\",\"Catalyst_Temperature__Bank_1_Sensor_2\",\n",
    "        \"Engine_kW__At_the_wheels_kW\",\"Engine_Load_Absolute_pct\",\"Engine_Oil_Temperature\",\"Engine_RPM_rpm\",\n",
    "        \"Fuel_flow_rate_hour_l_hr\",\"Fuel_Trim_Bank_1_Long_Term_pct\",\"Fuel_Trim_Bank_1_Short_Term_pct\",\n",
    "        \"Mass_Air_Flow_Rate_g_s\",\"O2_Sensor1_Wide_Range_Current_mA\",\"O2_Bank_1_Sensor_2_Voltage_V\",\n",
    "        \"Run_time_since_engine_start_s\",\"Timing_Advance\",\"Turbo_Boost_&_Vacuum_Gauge_psi\",\n",
    "        \"Voltage__Control_Module_V\",\"Volumetric_Efficiency__Calculated_pct\",\n",
    "        \"ECU_7EA:_Engine_Coolant_Temperature\",\"ECU_7EA:_Intake_Air_Temperature\",\n",
    "        \"ECU_7EB:_Ambient_air_temp\",\"ECU_7EB:_Engine_Load_pct\",\"ECU_7EB:_Engine_RPM_rpm\",\"ECU_7EB:_Speed__OBD_km_h\",\n",
    "    ]\n",
    "assert len(features) == 25\n",
    "\n",
    "# ----- Raw CSV column names (with punctuation) -----\n",
    "RAW_COLS = [\n",
    "    \"Air Fuel Ratio(Commanded)(:1)\",\"Air Fuel Ratio(Measured)(:1)\",\n",
    "    \"Catalyst Temperature (Bank 1 Sensor 1)\",\"Catalyst Temperature (Bank 1 Sensor 2)\",\n",
    "    \"Engine kW (At the wheels)(kW)\",\"Engine Load(Absolute)(%)\",\"Engine Oil Temperature\",\"Engine RPM(rpm)\",\n",
    "    \"Fuel flow rate/hour(l/hr)\",\"Fuel Trim Bank 1 Long Term(%)\",\"Fuel Trim Bank 1 Short Term(%)\",\n",
    "    \"Mass Air Flow Rate(g/s)\",\"O2 Sensor1 Wide Range Current(mA)\",\"O2 Bank 1 Sensor 2 Voltage(V)\",\n",
    "    \"Run time since engine start(s)\",\"Timing Advance\",\"Turbo Boost & Vacuum Gauge(psi)\",\n",
    "    \"Voltage (Control Module)(V)\",\"Volumetric Efficiency (Calculated)(%)\",\n",
    "    \"ECU(7EA): Engine Coolant Temperature\",\"ECU(7EA): Intake Air Temperature\",\n",
    "    \"ECU(7EB): Ambient air temp\",\"ECU(7EB): Engine Load(%)\",\"ECU(7EB): Engine RPM(rpm)\",\"ECU(7EB): Speed (OBD)(km/h)\",\n",
    "]\n",
    "TIMESTAMP_COL = \"timestamp\"\n",
    "\n",
    "# ----- Deterministic raw->canonical mapping (1:1) -----\n",
    "RAW_TO_CANON = {\n",
    "    \"Air Fuel Ratio(Commanded)(:1)\": \"Air_Fuel_Ratio_Commanded_:1\",\n",
    "    \"Air Fuel Ratio(Measured)(:1)\": \"Air_Fuel_Ratio_Measured_:1\",\n",
    "    \"Catalyst Temperature (Bank 1 Sensor 1)\": \"Catalyst_Temperature__Bank_1_Sensor_1\",\n",
    "    \"Catalyst Temperature (Bank 1 Sensor 2)\": \"Catalyst_Temperature__Bank_1_Sensor_2\",\n",
    "    \"Engine kW (At the wheels)(kW)\": \"Engine_kW__At_the_wheels_kW\",\n",
    "    \"Engine Load(Absolute)(%)\": \"Engine_Load_Absolute_pct\",\n",
    "    \"Engine Oil Temperature\": \"Engine_Oil_Temperature\",\n",
    "    \"Engine RPM(rpm)\": \"Engine_RPM_rpm\",\n",
    "    \"Fuel flow rate/hour(l/hr)\": \"Fuel_flow_rate_hour_l_hr\",\n",
    "    \"Fuel Trim Bank 1 Long Term(%)\": \"Fuel_Trim_Bank_1_Long_Term_pct\",\n",
    "    \"Fuel Trim Bank 1 Short Term(%)\": \"Fuel_Trim_Bank_1_Short_Term_pct\",\n",
    "    \"Mass Air Flow Rate(g/s)\": \"Mass_Air_Flow_Rate_g_s\",\n",
    "    \"O2 Sensor1 Wide Range Current(mA)\": \"O2_Sensor1_Wide_Range_Current_mA\",\n",
    "    \"O2 Bank 1 Sensor 2 Voltage(V)\": \"O2_Bank_1_Sensor_2_Voltage_V\",\n",
    "    \"Run time since engine start(s)\": \"Run_time_since_engine_start_s\",\n",
    "    \"Timing Advance\": \"Timing_Advance\",\n",
    "    \"Turbo Boost & Vacuum Gauge(psi)\": \"Turbo_Boost_&_Vacuum_Gauge_psi\",\n",
    "    \"Voltage (Control Module)(V)\": \"Voltage__Control_Module_V\",\n",
    "    \"Volumetric Efficiency (Calculated)(%)\": \"Volumetric_Efficiency__Calculated_pct\",\n",
    "    \"ECU(7EA): Engine Coolant Temperature\": \"ECU_7EA:_Engine_Coolant_Temperature\",\n",
    "    \"ECU(7EA): Intake Air Temperature\": \"ECU_7EA:_Intake_Air_Temperature\",\n",
    "    \"ECU(7EB): Ambient air temp\": \"ECU_7EB:_Ambient_air_temp\",\n",
    "    \"ECU(7EB): Engine Load(%)\": \"ECU_7EB:_Engine_Load_pct\",\n",
    "    \"ECU(7EB): Engine RPM(rpm)\": \"ECU_7EB:_Engine_RPM_rpm\",\n",
    "    \"ECU(7EB): Speed (OBD)(km/h)\": \"ECU_7EB:_Speed__OBD_km_h\",\n",
    "}\n",
    "assert set(RAW_TO_CANON.values()) == set(features)\n",
    "\n",
    "# ----- Windows-safe per-feature filename sanitizer (for KDE/GMM only) -----\n",
    "def sanitize_for_filename(feat: str) -> str:\n",
    "    return feat.replace(\":\", \"__COLON__\")\n",
    "\n",
    "# ----- Save the “single source of truth” model input contract -----\n",
    "MODEL_INPUT_CONTRACT = {\n",
    "    \"timestamp_column\": TIMESTAMP_COL,\n",
    "    \"features_canonical_order\": features,   # required order for ALL 5 models\n",
    "    \"raw_to_canonical_map\": RAW_TO_CANON,   # CSV→canonical\n",
    "    \"per_feature_filename_rule\": {\"colon\": \"__COLON__\"},  # used for KDE/GMM artifacts only\n",
    "    \"inference_expectation\": {\n",
    "        \"infer_ready_columns\": [\"row_hash\",\"timestamp\",\"source_id\",\"kafka_key\",\"offset\",\"source_file\",\"date\"] + features,\n",
    "        \"timestamp_tz\": \"UTC\",\n",
    "        \"feature_dtype\": \"float64 (castable to float32 for model input)\",\n",
    "        \"scaler\": \"RobustScaler(25th–75th) fitted on train only\"\n",
    "    }\n",
    "}\n",
    "(ARTIFACTS / \"model_input_contract.json\").write_text(json.dumps(MODEL_INPUT_CONTRACT, indent=2), encoding=\"utf-8\")\n",
    "print(\"Saved:\", ARTIFACTS / \"model_input_contract.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f89bc0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available : True\n",
      "CUDA device    : NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available :\", torch.cuda.is_available())\n",
    "print(\"CUDA device    :\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de9ed319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW shapes: (25439, 25) (6360, 25)\n",
      "Saved scaler & features.\n"
     ]
    }
   ],
   "source": [
    "# T-2 — Load CSV, rename to canonical, clean, split, scale\n",
    "\n",
    "assert DATA_CSV.exists(), f\"Missing data CSV: {DATA_CSV}\"\n",
    "df_raw = pd.read_csv(DATA_CSV)\n",
    "assert TIMESTAMP_COL in df_raw.columns\n",
    "assert set(RAW_COLS).issubset(df_raw.columns)\n",
    "\n",
    "# Rename\n",
    "df = df_raw[[TIMESTAMP_COL] + RAW_COLS].rename(columns={c: RAW_TO_CANON[c] for c in RAW_COLS})\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "# Drop rows with >30% missing across the 25 features (same rule as infer-ready writer)\n",
    "feat_df = df[features]\n",
    "keep_mask = feat_df.isna().mean(axis=1) <= 0.30\n",
    "df = df.loc[keep_mask].reset_index(drop=True)\n",
    "feat_df = df[features].astype(float)\n",
    "\n",
    "# Time sort (important for LSTM)\n",
    "df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "X = feat_df.values.astype(np.float32)\n",
    "\n",
    "# 80/20 split (time-based)\n",
    "split_idx = int(0.8 * len(df))\n",
    "X_train = X[:split_idx]\n",
    "X_val   = X[split_idx:]\n",
    "print(\"RAW shapes:\", X_train.shape, X_val.shape)\n",
    "\n",
    "# Scaling (fit on train only)\n",
    "scaler = RobustScaler(quantile_range=(25.0, 75.0))\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n",
    "\n",
    "joblib.dump(scaler, ARTIFACTS / \"scaler_robust.joblib\")\n",
    "(ARTIFACTS / \"features.json\").write_text(json.dumps(features, indent=2), encoding=\"utf-8\")\n",
    "print(\"Saved scaler & features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "817e3a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DenseAE] ep 1 tr=33.201632 va=43.421375\n",
      "[DenseAE] ep 20 tr=0.246179 va=0.393115\n",
      "[DenseAE] ep 40 tr=0.085552 va=0.172796\n",
      "[DenseAE] ep 60 tr=0.050019 va=0.136548\n",
      "[DenseAE] ep 80 tr=0.036052 va=0.100315\n",
      "[DenseAE] ep 100 tr=0.029672 va=0.085582\n",
      "[DenseAE] ep 120 tr=0.024741 va=0.073865\n",
      "[DenseAE] ep 140 tr=0.023720 va=0.086461\n",
      "[DenseAE] ep 160 tr=0.016935 va=0.057797\n",
      "[DenseAE] ep 180 tr=0.015978 va=0.052623\n",
      "[DenseAE] ep 200 tr=0.014596 va=0.050150\n",
      "[DenseAE] ep 220 tr=0.011402 va=0.043019\n",
      "[DenseAE] ep 240 tr=0.011075 va=0.035472\n",
      "[DenseAE] ep 260 tr=0.012298 va=0.034297\n",
      "[DenseAE] ep 280 tr=0.009241 va=0.032673\n",
      "[DenseAE] ep 300 tr=0.008677 va=0.030970\n",
      "[DenseAE] ep 320 tr=0.007531 va=0.039391\n",
      "[DenseAE] ep 340 tr=0.009405 va=0.040816\n",
      "[DenseAE] ep 360 tr=0.006290 va=0.025310\n",
      "[DenseAE] ep 380 tr=0.005496 va=0.022167\n",
      "[DenseAE] ep 400 tr=0.008814 va=0.027946\n",
      "Saved: C:\\engine_module_pipeline\\infer_stage\\artifacts\\model_dense_best_state_dict.pt C:\\engine_module_pipeline\\infer_stage\\artifacts\\model_dense_best_torchscript.pt C:\\engine_module_pipeline\\infer_stage\\artifacts\\dense_loss.png\n"
     ]
    }
   ],
   "source": [
    "# T-3 — Dense AE (TorchScript + SD) + loss plot\n",
    "\n",
    "torch.manual_seed(42); np.random.seed(42)\n",
    "input_dim = len(features)\n",
    "hidden = 128\n",
    "\n",
    "class DenseAE(nn.Module):\n",
    "    def __init__(self, d_in=input_dim, h=hidden):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Linear(d_in, h), nn.ReLU(),\n",
    "            nn.Linear(h, h//2), nn.ReLU(),\n",
    "        )\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.Linear(h//2, h), nn.ReLU(),\n",
    "            nn.Linear(h, d_in),\n",
    "        )\n",
    "    def forward(self, x):  # x: [B,F]\n",
    "        z = self.enc(x)\n",
    "        return self.dec(z)\n",
    "\n",
    "def train_dense(Xtr, Xva, epochs=400, batch=2048, lr=1e-3, patience=40):\n",
    "    dl_tr = DataLoader(torch.from_numpy(Xtr), batch_size=batch, shuffle=True)\n",
    "    dl_va = DataLoader(torch.from_numpy(Xva), batch_size=batch, shuffle=False)\n",
    "    model = DenseAE().to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    crit = nn.MSELoss()\n",
    "    best=np.inf; bad=0; best_state=None\n",
    "    hist_tr, hist_va = [], []\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train(); tr=0.0\n",
    "        for xb in dl_tr:\n",
    "            xb = xb.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "            yhat = model(xb)\n",
    "            loss = crit(yhat, xb)\n",
    "            loss.backward(); opt.step()\n",
    "            tr += loss.item() * xb.size(0)\n",
    "        tr /= len(Xtr)\n",
    "\n",
    "        model.eval(); va=0.0\n",
    "        with torch.no_grad():\n",
    "            for xb in dl_va:\n",
    "                xb = xb.to(DEVICE)\n",
    "                va += crit(model(xb), xb).item() * xb.size(0)\n",
    "        va /= max(1,len(Xva))\n",
    "        hist_tr.append(tr); hist_va.append(va)\n",
    "\n",
    "        if va < best - 1e-7:\n",
    "            best = va; best_state = {k:v.detach().cpu().clone() for k,v in model.state_dict().items()}; bad=0\n",
    "        else:\n",
    "            bad += 1\n",
    "        if bad >= patience: break\n",
    "        if ep % 20 == 0 or ep==1:\n",
    "            print(f\"[DenseAE] ep {ep} tr={tr:.6f} va={va:.6f}\")\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model, hist_tr, hist_va\n",
    "\n",
    "dense_model, tr_hist, va_hist = train_dense(X_train_s, X_val_s)\n",
    "\n",
    "# Save state dict (fallback for existing loader)\n",
    "DENSE_SD = ARTIFACTS / \"model_dense_best_state_dict.pt\"\n",
    "torch.save(dense_model.state_dict(), DENSE_SD)\n",
    "\n",
    "# Save TorchScript (preferred)\n",
    "dense_cpu = DenseAE().cpu(); dense_cpu.load_state_dict(torch.load(DENSE_SD, map_location=\"cpu\")); dense_cpu.eval()\n",
    "example = torch.from_numpy(X_val_s[:8] if len(X_val_s)>=8 else X_train_s[:8]).float()\n",
    "ts_dense = torch.jit.trace(dense_cpu, example)\n",
    "DENSE_TS = ARTIFACTS / \"model_dense_best_torchscript.pt\"\n",
    "ts_dense.save(str(DENSE_TS))\n",
    "\n",
    "# Loss plot\n",
    "plt.figure()\n",
    "plt.plot(tr_hist, label=\"train\"); plt.plot(va_hist, label=\"val\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"MSE\"); plt.legend(); plt.title(\"DenseAE Loss\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(ARTIFACTS / \"dense_loss.png\", dpi=150); plt.close()\n",
    "\n",
    "print(\"Saved:\", DENSE_SD, DENSE_TS, ARTIFACTS / \"dense_loss.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e915fcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq shapes: (25430, 10, 25) (6351, 10, 25)\n",
      "[LSTMAE] ep 1 tr=34.248627 va=49.941059\n",
      "[LSTMAE] ep 20 tr=8.664499 va=12.270056\n",
      "[LSTMAE] ep 40 tr=3.464946 va=4.210563\n",
      "[LSTMAE] ep 60 tr=1.821499 va=2.086655\n",
      "[LSTMAE] ep 80 tr=1.149877 va=1.407794\n",
      "[LSTMAE] ep 100 tr=0.786528 va=1.210577\n",
      "[LSTMAE] ep 120 tr=0.530290 va=0.994820\n",
      "[LSTMAE] ep 140 tr=0.530129 va=1.003904\n",
      "[LSTMAE] ep 160 tr=0.311875 va=0.856669\n",
      "[LSTMAE] ep 180 tr=0.235072 va=0.785827\n",
      "[LSTMAE] ep 200 tr=0.183451 va=0.785236\n",
      "[LSTMAE] ep 220 tr=0.154830 va=0.681515\n",
      "[LSTMAE] ep 240 tr=0.136194 va=0.659810\n",
      "[LSTMAE] ep 260 tr=0.105469 va=0.582793\n",
      "[LSTMAE] ep 280 tr=0.093608 va=0.545961\n",
      "[LSTMAE] ep 300 tr=0.081772 va=0.553259\n",
      "[LSTMAE] ep 320 tr=0.068287 va=0.546453\n",
      "[LSTMAE] ep 340 tr=0.061899 va=0.493811\n",
      "[LSTMAE] ep 360 tr=0.059055 va=0.462947\n",
      "[LSTMAE] ep 380 tr=0.050465 va=0.506958\n",
      "Saved: C:\\engine_module_pipeline\\infer_stage\\artifacts\\model_lstm_long_best.pt C:\\engine_module_pipeline\\infer_stage\\artifacts\\model_lstm_long_best_torchscript.pt C:\\engine_module_pipeline\\infer_stage\\artifacts\\lstm_loss.png\n"
     ]
    }
   ],
   "source": [
    "# T-4 — LSTM AE (TorchScript + SD named exactly as your loader expects)\n",
    "\n",
    "SEQ = 10  # causal windows, consistent with inference\n",
    "\n",
    "def build_sequences(X, seq=SEQ):\n",
    "    Xs = []\n",
    "    for i in range(seq-1, len(X)):\n",
    "        Xs.append(X[i-seq+1:i+1])\n",
    "    return np.stack(Xs, axis=0).astype(np.float32) if Xs else np.empty((0,seq,X.shape[1]), dtype=np.float32)\n",
    "\n",
    "Xtr_seq = build_sequences(X_train_s, SEQ)\n",
    "Xva_seq = build_sequences(X_val_s,   SEQ)\n",
    "print(\"Seq shapes:\", Xtr_seq.shape, Xva_seq.shape)\n",
    "\n",
    "class LSTMAE(nn.Module):\n",
    "    def __init__(self, d_in=len(features), enc_h=64, dec_h=64, layers=1):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.LSTM(input_size=d_in, hidden_size=enc_h, num_layers=layers, batch_first=True)\n",
    "        self.decoder = nn.LSTM(input_size=enc_h, hidden_size=dec_h, num_layers=layers, batch_first=True)\n",
    "        self.out = nn.Linear(dec_h, d_in)\n",
    "    def forward(self, x):             # x: [B,T,F]\n",
    "        enc_out,_ = self.encoder(x)   # [B,T,H]\n",
    "        dec_out,_ = self.decoder(enc_out)\n",
    "        y = self.out(dec_out[:,-1,:]) # last-step recon [B,F]\n",
    "        return y\n",
    "\n",
    "class SeqDS(Dataset):\n",
    "    def __init__(self, X): self.X = torch.from_numpy(X).float()\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i]\n",
    "\n",
    "def train_lstm(Xtr, Xva, epochs=400, batch=512, lr=1e-3, patience=40):\n",
    "    dl_tr = DataLoader(SeqDS(Xtr), batch_size=batch, shuffle=True)\n",
    "    dl_va = DataLoader(SeqDS(Xva), batch_size=batch, shuffle=False)\n",
    "    model = LSTMAE().to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    crit = nn.MSELoss()\n",
    "    best=np.inf; bad=0; best_state=None\n",
    "    tr_hist, va_hist = [], []\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train(); tr=0.0\n",
    "        for xb in dl_tr:\n",
    "            xb = xb.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "            yhat = model(xb)\n",
    "            y    = xb[:,-1,:]\n",
    "            loss = crit(yhat, y)\n",
    "            loss.backward(); opt.step()\n",
    "            tr += loss.item() * xb.size(0)\n",
    "        tr /= len(Xtr)\n",
    "\n",
    "        model.eval(); va=0.0\n",
    "        with torch.no_grad():\n",
    "            for xb in dl_va:\n",
    "                xb = xb.to(DEVICE)\n",
    "                yhat = model(xb); y = xb[:,-1,:]\n",
    "                va += crit(yhat, y).item() * xb.size(0)\n",
    "        va /= max(1,len(Xva))\n",
    "        tr_hist.append(tr); va_hist.append(va)\n",
    "\n",
    "        if va < best - 1e-7:\n",
    "            best = va; best_state = {k:v.detach().cpu().clone() for k,v in model.state_dict().items()}; bad=0\n",
    "        else:\n",
    "            bad += 1\n",
    "        if bad >= patience: break\n",
    "        if ep % 20 == 0 or ep==1:\n",
    "            print(f\"[LSTMAE] ep {ep} tr={tr:.6f} va={va:.6f}\")\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model, tr_hist, va_hist\n",
    "\n",
    "lstm_model, tr_l, va_l = train_lstm(Xtr_seq, Xva_seq)\n",
    "\n",
    "# Save state dict with the EXACT filename your inference loader expects\n",
    "LSTM_SD = ARTIFACTS / \"model_lstm_long_best.pt\"  # <- compatibility with your current loader\n",
    "torch.save(lstm_model.state_dict(), LSTM_SD)\n",
    "\n",
    "# TorchScript export (preferred; you can point ARTS['lstm_ts'] to this)\n",
    "lstm_cpu = LSTMAE().cpu(); lstm_cpu.load_state_dict(torch.load(LSTM_SD, map_location=\"cpu\")); lstm_cpu.eval()\n",
    "example = torch.from_numpy(Xva_seq[:8] if len(Xva_seq)>=8 else Xtr_seq[:8]).float()\n",
    "ts_lstm = torch.jit.trace(lstm_cpu, example)\n",
    "LSTM_TS = ARTIFACTS / \"model_lstm_long_best_torchscript.pt\"\n",
    "ts_lstm.save(str(LSTM_TS))\n",
    "\n",
    "# Loss plot\n",
    "plt.figure()\n",
    "plt.plot(tr_l, label=\"train\"); plt.plot(va_l, label=\"val\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"MSE\"); plt.legend(); plt.title(\"LSTMAE Loss (last-step)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(ARTIFACTS / \"lstm_loss.png\", dpi=150); plt.close()\n",
    "\n",
    "print(\"Saved:\", LSTM_SD, LSTM_TS, ARTIFACTS / \"lstm_loss.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c69f19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\engine_module_pipeline\\infer_stage\\artifacts\\isolation_forest_combiner_final.joblib\n"
     ]
    }
   ],
   "source": [
    "# T-5 — Isolation Forest on scaled rows (global, not per-feature)\n",
    "\n",
    "iso = IsolationForest(\n",
    "    n_estimators=400,\n",
    "    max_samples=\"auto\",\n",
    "    contamination=\"auto\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "iso.fit(X_train_s)\n",
    "ISOF_PATH = ARTIFACTS / \"isolation_forest_combiner_final.joblib\"\n",
    "joblib.dump(iso, ISOF_PATH)\n",
    "print(\"Saved:\", ISOF_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f712e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved KDE/GMM indices (25/25).\n"
     ]
    }
   ],
   "source": [
    "# T-6 — KDE & GMM per-feature with Windows-safe filenames + index JSONs\n",
    "\n",
    "KDE_BW     = 0.2\n",
    "GMM_MAX_K  = 5\n",
    "\n",
    "kde_index = {}\n",
    "gmm_index = {}\n",
    "\n",
    "for j, feat in enumerate(features):\n",
    "    v = X_train_s[:, j].reshape(-1, 1)\n",
    "\n",
    "    # KDE\n",
    "    kde = KernelDensity(kernel=\"gaussian\", bandwidth=KDE_BW)\n",
    "    kde.fit(v)\n",
    "    kde_fname = f\"kde_{sanitize_for_filename(feat)}.joblib\"\n",
    "    joblib.dump(kde, ARTIFACTS / kde_fname)\n",
    "    kde_index[feat] = kde_fname\n",
    "\n",
    "    # GMM (best by BIC)\n",
    "    best_bic = np.inf; best_gmm = None\n",
    "    for k in range(1, GMM_MAX_K+1):\n",
    "        gmm = GaussianMixture(n_components=k, covariance_type=\"full\", random_state=42)\n",
    "        gmm.fit(v)\n",
    "        bic = gmm.bic(v)\n",
    "        if bic < best_bic:\n",
    "            best_bic, best_gmm = bic, gmm\n",
    "    gmm_fname = f\"gmm_{sanitize_for_filename(feat)}.joblib\"\n",
    "    joblib.dump(best_gmm, ARTIFACTS / gmm_fname)\n",
    "    gmm_index[feat] = gmm_fname\n",
    "\n",
    "# Index JSONs (canonical feature -> actual filename)\n",
    "(ARTIFACTS / \"kde_index.json\").write_text(json.dumps(kde_index, indent=2), encoding=\"utf-8\")\n",
    "(ARTIFACTS / \"gmm_index.json\").write_text(json.dumps(gmm_index, indent=2), encoding=\"utf-8\")\n",
    "print(\"Saved KDE/GMM indices (25/25).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3582ecfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved baselines and manifest.\n"
     ]
    }
   ],
   "source": [
    "# T-7 — Baselines (median/MAD + mean/std) and runtime manifest\n",
    "\n",
    "import numpy as np, json, joblib, pandas as pd, torch\n",
    "from pathlib import Path\n",
    "\n",
    "def robust_stats(a):\n",
    "    a = np.asarray(a).ravel()\n",
    "    a = a[np.isfinite(a)]\n",
    "    if a.size == 0:\n",
    "        return {\"median\": 0.0, \"mad\": 1.0, \"mean\": 0.0, \"std\": 1.0}\n",
    "    med = float(np.median(a))\n",
    "    mad = float(np.median(np.abs(a - med)) + 1e-9)\n",
    "    mu  = float(np.mean(a))\n",
    "    sd  = float(np.std(a) + 1e-9)\n",
    "    return {\"median\": med, \"mad\": mad, \"mean\": mu, \"std\": sd}\n",
    "\n",
    "# Dense recon errors on val (TorchScript)\n",
    "dense_cpu = torch.jit.load(str(ARTIFACTS / \"model_dense_best_torchscript.pt\"), map_location=\"cpu\").eval()\n",
    "with torch.no_grad():\n",
    "    xt = torch.from_numpy(X_val_s).float()\n",
    "    recon = dense_cpu(xt).numpy()\n",
    "dense_err = ((X_val_s - recon)**2).mean(axis=1)\n",
    "\n",
    "# LSTM last-step recon errors on val (TorchScript)\n",
    "lstm_cpu = torch.jit.load(str(ARTIFACTS / \"model_lstm_long_best_torchscript.pt\"), map_location=\"cpu\").eval()\n",
    "\n",
    "def make_seq(X, seq=10):\n",
    "    if len(X) < seq: return np.empty((0,seq,X.shape[1]), dtype=np.float32)\n",
    "    out = []\n",
    "    for i in range(seq-1, len(X)):\n",
    "        out.append(X[i-seq+1:i+1])\n",
    "    return np.stack(out, axis=0).astype(np.float32)\n",
    "\n",
    "Xva_seq = make_seq(X_val_s, 10)\n",
    "if len(Xva_seq) > 0:\n",
    "    with torch.no_grad():\n",
    "        yhat = lstm_cpu(torch.from_numpy(Xva_seq).float()).numpy()\n",
    "    y = Xva_seq[:,-1,:]\n",
    "    lstm_err = ((y - yhat)**2).mean(axis=1)\n",
    "else:\n",
    "    lstm_err = np.array([])\n",
    "\n",
    "# Isolation Forest decision function\n",
    "iso_scores = joblib.load(ARTIFACTS / \"isolation_forest_combiner_final.joblib\").decision_function(X_val_s)\n",
    "\n",
    "# KDE/GMM aggregate log-prob — NOTE: GMM uses score_samples now (not score)\n",
    "def aggregate_logp(index_name, kind):\n",
    "    idx = json.loads((ARTIFACTS / index_name).read_text(encoding=\"utf-8\"))\n",
    "    vals = []\n",
    "    for r in range(len(X_val_s)):\n",
    "        s, cnt = 0.0, 0\n",
    "        for j, feat in enumerate(features):\n",
    "            fname = idx.get(feat)\n",
    "            if not fname:\n",
    "                continue\n",
    "            model = joblib.load(ARTIFACTS / fname)\n",
    "            x = float(X_val_s[r, j])\n",
    "            try:\n",
    "                if kind == \"kde\":\n",
    "                    s += float(model.score_samples([[x]])[0]); cnt += 1\n",
    "                else:  # gmm\n",
    "                    # CRITICAL FIX: per-sample log-likelihood, not averaged score()\n",
    "                    s += float(model.score_samples([[x]])[0]); cnt += 1\n",
    "            except Exception:\n",
    "                # swallow per-feature issues to keep aggregate robust\n",
    "                pass\n",
    "        vals.append(s if cnt > 0 else np.nan)\n",
    "    return np.array(vals)\n",
    "\n",
    "kde_lp = aggregate_logp(\"kde_index.json\", \"kde\")\n",
    "gmm_lp = aggregate_logp(\"gmm_index.json\", \"gmm\")\n",
    "\n",
    "# Baselines dictionary (used by inference robust normalization)\n",
    "BASELINES = {\n",
    "    \"dense\": robust_stats(dense_err),\n",
    "    \"lstm\":  robust_stats(lstm_err),\n",
    "    \"isof\":  robust_stats(iso_scores),\n",
    "    \"kde\":   robust_stats(kde_lp),\n",
    "    \"gmm\":   robust_stats(gmm_lp),\n",
    "}\n",
    "(ARTIFACTS / \"scoring_summary.json\").write_text(json.dumps(BASELINES, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "manifest = {\n",
    "    \"created_utc\": pd.Timestamp.utcnow().isoformat(),\n",
    "    \"features_canonical_order\": features,\n",
    "    \"raw_to_canonical_map\": RAW_TO_CANON,\n",
    "    \"scaler_file\": \"scaler_robust.joblib\",\n",
    "    \"dense_torchscript\": \"model_dense_best_torchscript.pt\",\n",
    "    \"dense_state_dict\": \"model_dense_best_state_dict.pt\",\n",
    "    \"lstm_torchscript\": \"model_lstm_long_best_torchscript.pt\",\n",
    "    \"lstm_state_dict_compat\": \"model_lstm_long_best.pt\",  # compatibility filename\n",
    "    \"isolation_forest_joblib\": \"isolation_forest_combiner_final.joblib\",\n",
    "    \"kde_index_file\": \"kde_index.json\",\n",
    "    \"gmm_index_file\": \"gmm_index.json\",\n",
    "    \"filename_sanitizer\": {\"colon\": \"__COLON__\"},  # unchanged\n",
    "    \"model_input_contract_file\": \"model_input_contract.json\"\n",
    "}\n",
    "(ARTIFACTS / \"runtime_manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "print(\"Saved baselines and manifest.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38dc88d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts created in: C:\\engine_module_pipeline\\infer_stage\\artifacts\n",
      "Files: ['dense_loss.png', 'features.json', 'gmm_Air_Fuel_Ratio_Commanded___COLON__1.joblib', 'gmm_Air_Fuel_Ratio_Measured___COLON__1.joblib', 'gmm_Catalyst_Temperature__Bank_1_Sensor_1.joblib', 'gmm_Catalyst_Temperature__Bank_1_Sensor_2.joblib', 'gmm_ECU_7EA__COLON___Engine_Coolant_Temperature.joblib', 'gmm_ECU_7EA__COLON___Intake_Air_Temperature.joblib', 'gmm_ECU_7EB__COLON___Ambient_air_temp.joblib', 'gmm_ECU_7EB__COLON___Engine_Load_pct.joblib', 'gmm_ECU_7EB__COLON___Engine_RPM_rpm.joblib', 'gmm_ECU_7EB__COLON___Speed__OBD_km_h.joblib', 'gmm_Engine_Load_Absolute_pct.joblib', 'gmm_Engine_Oil_Temperature.joblib', 'gmm_Engine_RPM_rpm.joblib', 'gmm_Engine_kW__At_the_wheels_kW.joblib', 'gmm_Fuel_Trim_Bank_1_Long_Term_pct.joblib', 'gmm_Fuel_Trim_Bank_1_Short_Term_pct.joblib', 'gmm_Fuel_flow_rate_hour_l_hr.joblib', 'gmm_Mass_Air_Flow_Rate_g_s.joblib', 'gmm_O2_Bank_1_Sensor_2_Voltage_V.joblib', 'gmm_O2_Sensor1_Wide_Range_Current_mA.joblib', 'gmm_Run_time_since_engine_start_s.joblib', 'gmm_Timing_Advance.joblib', 'gmm_Turbo_Boost_&_Vacuum_Gauge_psi.joblib', 'gmm_Voltage__Control_Module_V.joblib', 'gmm_Volumetric_Efficiency__Calculated_pct.joblib', 'gmm_index.json', 'isolation_forest_combiner_final.joblib', 'kde_Air_Fuel_Ratio_Commanded___COLON__1.joblib', 'kde_Air_Fuel_Ratio_Measured___COLON__1.joblib', 'kde_Catalyst_Temperature__Bank_1_Sensor_1.joblib', 'kde_Catalyst_Temperature__Bank_1_Sensor_2.joblib', 'kde_ECU_7EA__COLON___Engine_Coolant_Temperature.joblib', 'kde_ECU_7EA__COLON___Intake_Air_Temperature.joblib', 'kde_ECU_7EB__COLON___Ambient_air_temp.joblib', 'kde_ECU_7EB__COLON___Engine_Load_pct.joblib', 'kde_ECU_7EB__COLON___Engine_RPM_rpm.joblib', 'kde_ECU_7EB__COLON___Speed__OBD_km_h.joblib', 'kde_Engine_Load_Absolute_pct.joblib', 'kde_Engine_Oil_Temperature.joblib', 'kde_Engine_RPM_rpm.joblib', 'kde_Engine_kW__At_the_wheels_kW.joblib', 'kde_Fuel_Trim_Bank_1_Long_Term_pct.joblib', 'kde_Fuel_Trim_Bank_1_Short_Term_pct.joblib', 'kde_Fuel_flow_rate_hour_l_hr.joblib', 'kde_Mass_Air_Flow_Rate_g_s.joblib', 'kde_O2_Bank_1_Sensor_2_Voltage_V.joblib', 'kde_O2_Sensor1_Wide_Range_Current_mA.joblib', 'kde_Run_time_since_engine_start_s.joblib', 'kde_Timing_Advance.joblib', 'kde_Turbo_Boost_&_Vacuum_Gauge_psi.joblib', 'kde_Voltage__Control_Module_V.joblib', 'kde_Volumetric_Efficiency__Calculated_pct.joblib', 'kde_index.json', 'lstm_loss.png', 'model_dense_best_state_dict.pt', 'model_dense_best_torchscript.pt', 'model_input_contract.json', 'model_lstm_long_best.pt', 'model_lstm_long_best_torchscript.pt', 'runtime_manifest.json', 'scaler_robust.joblib', 'scoring_summary.json']\n",
      "\n",
      "Dense val MSE ~ 0.019481489434838295\n",
      "LSTM  val MSE ~ 0.4576328694820404\n",
      "IF    decision_function stats: {'min': -0.16901223324508186, 'max': 0.13381472068887434, 'mean': 0.059691490237622866}\n",
      "KDE   agg logp ~ -28.59189826355938\n",
      "GMM   agg logp ~ 13.03705529223527\n"
     ]
    }
   ],
   "source": [
    "# T-8 — quick sanity\n",
    "print(\"Artifacts created in:\", ARTIFACTS)\n",
    "print(\"Files:\", sorted([p.name for p in ARTIFACTS.iterdir()]))\n",
    "\n",
    "print(\"\\nDense val MSE ~\", float(np.mean(dense_err)) if len(dense_err) else None)\n",
    "print(\"LSTM  val MSE ~\", float(np.mean(lstm_err)) if len(lstm_err) else None)\n",
    "print(\"IF    decision_function stats:\", {\n",
    "    \"min\": float(np.nanmin(iso_scores)), \"max\": float(np.nanmax(iso_scores)),\n",
    "    \"mean\": float(np.nanmean(iso_scores))\n",
    "})\n",
    "print(\"KDE   agg logp ~\", float(np.nanmean(kde_lp)) if np.isfinite(kde_lp).any() else None)\n",
    "print(\"GMM   agg logp ~\", float(np.nanmean(gmm_lp)) if np.isfinite(gmm_lp).any() else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a227ec86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f481ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b601da1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9c8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch CUDA (cu121)",
   "language": "python",
   "name": "torchcuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
